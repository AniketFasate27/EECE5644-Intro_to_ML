{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 259\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# Part B\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;124;03msamples = generate_data(mean_0, mean_1, cov_0_incorrect, cov_1_incorrect)\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;124;03mwrite_sample_data(samples=samples, save_path=incorrect_samples_path)\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;124;03mplot_samples(samples_path=incorrect_samples_path, save_path='incorrect_samples_scatterplot.pdf')\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m--> 259\u001b[0m \u001b[43mimplement_classifier_and_plot_roc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mincorrect_samples_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov_0_incorrect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov_1_incorrect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./incorrect_ROC_curve.pdf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 175\u001b[0m, in \u001b[0;36mimplement_classifier_and_plot_roc_curve\u001b[1;34m(samples_path, mean_0, mean_1, cov_0, cov_1, save_path)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# Fill array with calculated discriminants and add to DataFrame\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, samples\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m--> 175\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[43msamples\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mto_numpy()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    176\u001b[0m     discriminant \u001b[38;5;241m=\u001b[39m multivariate_normal\u001b[38;5;241m.\u001b[39mpdf(sample, mean_1, cov_1)\u001b[38;5;241m/\u001b[39mmultivariate_normal\u001b[38;5;241m.\u001b[39mpdf(sample, mean_0, cov_0)\n\u001b[0;32m    177\u001b[0m     discriminants\u001b[38;5;241m.\u001b[39mappend(discriminant)\n",
      "File \u001b[1;32mc:\\Users\\anifa\\.conda\\envs\\aniket\\lib\\site-packages\\pandas\\core\\indexing.py:1103\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1100\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1102\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m-> 1103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anifa\\.conda\\envs\\aniket\\lib\\site-packages\\pandas\\core\\indexing.py:1658\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1655\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_integer(key, axis)\n\u001b[1;32m-> 1658\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ixs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anifa\\.conda\\envs\\aniket\\lib\\site-packages\\pandas\\core\\frame.py:3652\u001b[0m, in \u001b[0;36mDataFrame._ixs\u001b[1;34m(self, i, axis)\u001b[0m\n\u001b[0;32m   3650\u001b[0m \u001b[38;5;66;03m# irow\u001b[39;00m\n\u001b[0;32m   3651\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 3652\u001b[0m     new_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfast_xs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3654\u001b[0m     \u001b[38;5;66;03m# if we are a copy, mark as such\u001b[39;00m\n\u001b[0;32m   3655\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(new_mgr\u001b[38;5;241m.\u001b[39marray, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m new_mgr\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39mbase \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anifa\\.conda\\envs\\aniket\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1082\u001b[0m, in \u001b[0;36mBlockManager.fast_xs\u001b[1;34m(self, loc)\u001b[0m\n\u001b[0;32m   1079\u001b[0m     result \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mconstruct_array_type()\u001b[38;5;241m.\u001b[39m_from_sequence(result, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1081\u001b[0m block \u001b[38;5;241m=\u001b[39m new_block(result, placement\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(result)), ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSingleBlockManager\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anifa\\.conda\\envs\\aniket\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1858\u001b[0m, in \u001b[0;36mSingleBlockManager.__init__\u001b[1;34m(self, block, axis, verify_integrity)\u001b[0m\n\u001b[0;32m   1847\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m   1848\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1849\u001b[0m     block: Block,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1854\u001b[0m     \u001b[38;5;66;03m# assert isinstance(block, Block), type(block)\u001b[39;00m\n\u001b[0;32m   1855\u001b[0m     \u001b[38;5;66;03m# assert isinstance(axis, Index), type(axis)\u001b[39;00m\n\u001b[0;32m   1857\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes \u001b[38;5;241m=\u001b[39m [axis]\n\u001b[1;32m-> 1858\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m (block,)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from numpy.random import default_rng\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib as mpl \n",
    "import math\n",
    "import random\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "def generate_data(mean_0, mean_1, cov_0, cov_1):\n",
    "    '''\n",
    "    Generate 10000 samples according to a multivariate Gaussian probability density function, \n",
    "    keeping track of the true class labels for each sample. Includes the 4 dimensions plus a\n",
    "    0 or 1 to track true class labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    samples: numpy.array\n",
    "        The generated sample data\n",
    "    '''\n",
    "    rng = default_rng()\n",
    "    overall_size = 10000\n",
    "    p_0 = 0.7\n",
    "    p_1 = 0.3\n",
    "    size_0 = 0\n",
    "    size_1 = 0\n",
    "    for i in range(0, overall_size) :\n",
    "        if(random.random() < p_0):\n",
    "            size_0 = size_0 + 1\n",
    "        else:\n",
    "            size_1 = size_1 + 1\n",
    "\n",
    "    samples_0 = rng.multivariate_normal(mean=mean_0, cov=cov_0, size=size_0)\n",
    "    samples_0 = pd.DataFrame(samples_0, columns=['x','y','z','t'])\n",
    "    samples_0['True Class Label'] = 0\n",
    "    samples_1 = rng.multivariate_normal(mean=mean_1, cov=cov_1, size=size_1)\n",
    "    samples_1 = pd.DataFrame(samples_1, columns=['x','y','z','t'])\n",
    "    samples_1['True Class Label'] = 1\n",
    "    samples   = samples_0.append(samples_1)\n",
    "    return samples\n",
    "\n",
    "def write_sample_data(samples, save_path):\n",
    "    '''\n",
    "    Saves the sample data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    samples: numpy.array\n",
    "        The generated sample data\n",
    "    save_path: string\n",
    "        File name and path to save the sample data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    '''\n",
    "    samples.to_csv(save_path)\n",
    "\n",
    "def read_sample_data(save_path):\n",
    "    '''\n",
    "    Read the sample data. Helper function to read data in other functions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    save_path: string\n",
    "        File containing the sample data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    samples: pandas.DataFrame\n",
    "        The generated sample data\n",
    "    '''\n",
    "    samples = pd.read_csv(save_path, index_col=0)\n",
    "    return samples\n",
    "\n",
    "def plot_samples(samples_path, save_path='samples_scatterplot.pdf'):\n",
    "    '''\n",
    "    Plots the four-dimensions of the samples taken from the distribution.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    samples_path: string\n",
    "        File containing the sample data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    '''\n",
    "    samples = read_sample_data(save_path=samples_path)\n",
    "    fig = plt.figure(figsize = (10, 7))\n",
    "    fig.subplots_adjust(left=0.01, right=0.99, top=0.96, bottom=0.04, wspace=0)\n",
    "    ax = plt.axes(projection =\"3d\")\n",
    "    samples = samples.sort_values('t')\n",
    "    samples_0 = samples[samples['True Class Label']==0]\n",
    "    samples_1 = samples[samples['True Class Label']==1]\n",
    "    x_0 = samples_0['x'].tolist()\n",
    "    y_0 = samples_0['y'].tolist()\n",
    "    z_0 = samples_0['z'].tolist()\n",
    "    t_0 = samples_0['t'].tolist()\n",
    "    x_1 = samples_1['x'].tolist()\n",
    "    y_1 = samples_1['y'].tolist()\n",
    "    z_1 = samples_1['z'].tolist()\n",
    "    t_1 = samples_1['t'].tolist()\n",
    "    C = np.linspace(-5, 5, len(t_0))\n",
    "    scamap = plt.cm.ScalarMappable(cmap='YlOrRd')\n",
    "    fcolors = scamap.to_rgba(C)\n",
    "    ax.scatter3D(x_0, y_0, z_0, facecolors=fcolors, cmap='YlOrRd', label='0')\n",
    "    C = np.linspace(-5, 5, len(t_1))\n",
    "    scamap = plt.cm.ScalarMappable(cmap='PuBuGn')\n",
    "    fcolors = scamap.to_rgba(C)\n",
    "    ax.scatter3D(x_1, y_1, z_1, facecolors=fcolors, cmap='PuBuGn', label='1')\n",
    "    ax.set_title(\"Samples from Multivariate Gaussian Distributions\")\n",
    "    ax.set_xlabel('1st Dimension, x')\n",
    "    ax.set_ylabel('2nd Dimension, y')\n",
    "    ax.set_zlabel('3rd Dimension, z')\n",
    "    plt.savefig(save_path)\n",
    "    plt.clf()\n",
    "    \n",
    "    # Make colorbar \n",
    "    fig, axes = plt.subplots(1,2,figsize=(8,1.2))\n",
    "    fig.suptitle('True Class Labels')\n",
    "    fig.text(0.5, 0.08, '4th Dimension, t', ha='center', va='center')\n",
    "    cmap = plt.cm.get_cmap('YlOrRd')\n",
    "    colors = cmap(np.arange(cmap.N))\n",
    "    axes[0].imshow([colors], extent=[min(t_0), max(t_0), 0, 1])\n",
    "    axes[0].set_yticklabels([])\n",
    "    axes[0].set_yticks([])\n",
    "    axes[0].set_ylim(0,1)\n",
    "    axes[0].set_xlim(math.ceil(min(t_0)),math.floor(max(t_0)))\n",
    "    axes[0].set_title('Class 0')\n",
    "\n",
    "    cmap = plt.cm.get_cmap('PuBuGn')\n",
    "    colors = cmap(np.arange(cmap.N))\n",
    "    axes[1].imshow([colors], extent=[min(t_1), max(t_1), 0, 1])\n",
    "    axes[1].set_yticklabels([])\n",
    "    axes[1].set_yticks([])\n",
    "    axes[1].set_ylim(0,1)\n",
    "    axes[1].set_xlim(math.ceil(min(t_1)),math.floor(max(t_1)))\n",
    "    axes[1].set_title('Class 1')\n",
    "\n",
    "    plt.savefig('samples_scatterplot_legend.pdf')\n",
    "    plt.clf()\n",
    "    return None\n",
    "\n",
    "def implement_classifier_and_plot_roc_curve(samples_path, mean_0, mean_1, cov_0, cov_1, save_path='./ROC_curve.pdf'):\n",
    "    '''\n",
    "    Plots the minimum risk and ROC curve with theorectical and experimental probabilites.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    samples_path: string\n",
    "        File containing the sample data\n",
    "    mean_0, mean_1: array\n",
    "        The vectors of mu for the two classes.\n",
    "    cov_0, cov_1: double array\n",
    "        The matrixes of sigma for the two classes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    exp_min: dict\n",
    "        Info of the experimental minimum error.\n",
    "    thy_min: dict\n",
    "        Info of the theorectical minimum error.\n",
    "    '''\n",
    "    # Prep the sample data\n",
    "    samples   = read_sample_data(save_path=samples_path)\n",
    "    # Initialize empty arrays to store discriminant scores\n",
    "    discriminants = []\n",
    "    # Fill array with calculated discriminants and add to DataFrame\n",
    "    for i in range(0, samples.shape[0]):\n",
    "        sample = samples.iloc[i].to_numpy()[:-1]\n",
    "        discriminant = multivariate_normal.pdf(sample, mean_1, cov_1)/multivariate_normal.pdf(sample, mean_0, cov_0)\n",
    "        discriminants.append(discriminant)\n",
    "    samples['Discriminant'] = discriminants\n",
    "    samples = samples.sort_values('Discriminant')\n",
    "    dis_0 = samples[samples['True Class Label']==0]['Discriminant'].tolist()\n",
    "    dis_1 = samples[samples['True Class Label']==1]['Discriminant'].tolist()\n",
    "    df = pd.DataFrame(columns=['False Positive', 'True Positive', 'Gamma', 'Probability Error'])\n",
    "    for index, row in samples.iterrows():\n",
    "        discriminant   = row['Discriminant'] \n",
    "        false_positive = len([class_dis for class_dis in dis_0 if class_dis>=discriminant])/len(dis_0)\n",
    "        true_positive = len([class_dis for class_dis in dis_1 if class_dis>=discriminant])/len(dis_1)\n",
    "        p_err = false_positive*0.7+(1-true_positive)*0.3\n",
    "        d = {'False Positive': false_positive, 'True Positive': true_positive, \n",
    "             'Gamma': discriminant, 'Probability Error': p_err}\n",
    "        df = df.append(d, ignore_index=True)\n",
    "    df = df.sort_values('Probability Error')\n",
    "    # Get info of minimum experimental probablility error\n",
    "    exp_min = df.iloc[0]\n",
    "    print('Experimental Mimimum Error Info:\\n')\n",
    "    print(exp_min)\n",
    "    # Calculate theorectical error\n",
    "    thy_gamma = 0.7/0.3\n",
    "    thy_lambdas = [len([class_dis for class_dis in dis_0 if class_dis>=thy_gamma])/len(dis_0),\n",
    "                len([class_dis for class_dis in dis_1 if class_dis>=thy_gamma])/len(dis_1)]\n",
    "    thy_p_err = thy_lambdas[0]*0.7 + (1-thy_lambdas[1])*0.3\n",
    "    thy_min = {'False Positive': thy_lambdas[0], 'True Positive': thy_lambdas[1], 'Gamma': thy_gamma, 'Probability Error': thy_p_err}\n",
    "    print('Theoretical Mimimum Error Info:\\n')\n",
    "    print(thy_min)\n",
    "    fig, ax = plt.subplots(1,1, figsize=(5,5))\n",
    "    # Plot ROC curve\n",
    "    ax.plot(df['False Positive'], df['True Positive'], 'ro', markersize=4)\n",
    "    # Plot experimental minimum\n",
    "    ax.plot(exp_min['False Positive'], exp_min['True Positive'], 'bo', label='Experimental', markersize=10)\n",
    "    # Plot theorectical minimum\n",
    "    ax.plot(thy_min['False Positive'], thy_min['True Positive'], 'go', label='Theoretical', markersize=10)\n",
    "    ax.legend(title='Minimum Error Probabilities', loc='lower right')\n",
    "    #ax.set_title('Minimum Expected Risk ROC Curve')\n",
    "    ax.set_xlabel('Probability of False Positive')\n",
    "    ax.set_ylabel('Probability of True Positive')\n",
    "    ax.yaxis.grid(color='lightgrey', linestyle=':')\n",
    "    ax.xaxis.grid(color='lightgrey', linestyle=':')\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.set_xlim(0,1)\n",
    "    ax.set_ylim(0,1)\n",
    "    #ax.set_xscale('log')\n",
    "    #ax.set_yscale('log')\n",
    "    plt.savefig(save_path)\n",
    "    return exp_min, thy_min \n",
    "\n",
    "if __name__=='__main__':\n",
    "    samples_path = './question_one_samples.csv'\n",
    "    mean_0 = [-1, 1, -1, 1]\n",
    "    mean_1 = [1, 1, 1, 1]\n",
    "    cov_0  = [[2,    -0.5,  0.3,  0],\n",
    "            [-0.5, 1,     -0.5, 0],\n",
    "            [0.3,  -0.5,  1,    0],\n",
    "            [0,    0,     0,    2]]\n",
    "    cov_1  = [[1,     0.3,  -0.2, 0],\n",
    "            [0.3,   2,    0.3,  0],\n",
    "            [-0.2,  0.3,  1,    0],\n",
    "            [0,     0,    0,    3]]\n",
    "    incorrect_samples_path = './question_one_incorrect_sample.csv'\n",
    "    cov_0_incorrect  = [[2,    0,     0,    0],\n",
    "                        [0,    1,     0,    0],\n",
    "                        [0,    0,     1,    0],\n",
    "                        [0,    0,     0,    2]]\n",
    "    cov_1_incorrect  = [[1,     0,    0,    0],\n",
    "                        [0,     2,    0,    0],\n",
    "                        [0,     0,    1,    0],\n",
    "                        [0,     0,    0,    3]]\n",
    "    # Part A\n",
    "    '''\n",
    "    samples = generate_data(mean_0, mean_1, cov_0, cov_1)\n",
    "    write_sample_data(samples=samples, save_path=samples_path)\n",
    "    plot_samples(samples_path=samples_path)\n",
    "    implement_classifier_and_plot_roc_curve(samples_path, mean_0, mean_1, cov_0, cov_1)\n",
    "    '''\n",
    "    # Part B\n",
    "    '''\n",
    "    samples = generate_data(mean_0, mean_1, cov_0_incorrect, cov_1_incorrect)\n",
    "    write_sample_data(samples=samples, save_path=incorrect_samples_path)\n",
    "    plot_samples(samples_path=incorrect_samples_path, save_path='incorrect_samples_scatterplot.pdf')\n",
    "    '''\n",
    "    implement_classifier_and_plot_roc_curve(incorrect_samples_path, mean_0, mean_1, cov_0_incorrect, cov_1_incorrect, save_path='./incorrect_ROC_curve.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aniket",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
